{"name":"sr-captcha","tagline":"","body":"Breaking The Silk Road Captcha\r\n==============================\r\n\r\n[Mike A. Owens](http://mike.filespanker.com/), August 24th, 2014\r\n\r\nThe Silk Road, the infamous online black market, was shut down almost a year\r\nback.  Until moments ago, I thought it had stayed dead.  That would've made it\r\neasier to publish this write-up, but what the hell.\r\n\r\nI've just read that it's back in operation, but I doubt anything written here\r\napplies anymore.  Regardless, I'd like to dive into some code I wrote years ago\r\nthat I'm particularly fond of, but obviously reluctant to put on a resumé.\r\n\r\n\r\nMotivation\r\n------------\r\nI first heard of The Silk Road via\r\n[gwern's writings](http://www.gwern.net/Silk%20Road) on the subject, probably\r\nthrough an HN submission.  After jumping through a few Tor hoops, I was able to\r\ncheck out the listings.  \r\n\r\nNow, personally, I won't even take over-the-counter medications that are\r\n\"too blue\", for fear that they'll make me drowsy.  But my first thought was:\r\nHere is a bunch of interesting, real-time, market data that's hard to access\r\nprogrammatically.\r\n\r\nA [Drug Wars](http://en.wikipedia.org/wiki/Drugwars) with real-time price updates?  \r\n\r\nA market ticker that tells you `MJ ▲0.21`, `COKE ▼3.53`?\r\n\r\nOver time, I could collect a huge amount of historical pricing data for illicit\r\nsubstances.  That's *got* to end up useful, somehow.  \r\n\r\nNo matter: I had already started imagining charts, graphs,\r\nand `Sr::Listing` instances.  But first I had to get this login automated.\r\n\r\nI'll be interspersing this article with, what I consider, interesting, (edited),\r\nsnippets of code.  I won't be publishing the API package, as:\r\n\r\n  1. It probably doesn't work anymore, and I'm years removed from it.  It\r\n     involved a lot of scraping of the site, which is always brittle.\r\n  2. It was never really production quality, as evidenced by a lot more\r\n     \"shell outs\" than I'd like.\r\n\r\nAll listings are in Ruby.\r\n\r\nTor\r\n---\r\nThe Silk Road was implemented as a TOR hidden service.  For my client API to\r\nconnect to it and do anything useful, it has talk Tor.\r\n\r\nThe Vidalia software starts a local SOCKS5 proxy when launched.  My client\r\nneeded to configure its HTTP agents to use it.  Luckily, the\r\n[socksify gem](https://github.com/astro/socksify-ruby) allows me to do just\r\nthat.  This hacky approach changes the SOCKS proxy state of every socket in the\r\napplication after it's `auto_configure!`ed, though.\r\n\r\n\r\n```ruby\r\nrequire 'socksify'\r\nrequire 'socksify/http'\r\n\r\nmodule Sr\r\n\r\n  class TorError < RuntimeError; end\r\n\r\n  class Tor\r\n\r\n    # Loads the torproject test page and tests for the success message.\r\n    # Just to be sure.\r\n    def self.test_tor?\r\n      uri = 'https://check.torproject.org/?lang=en-US'\r\n      begin\r\n        page = Net::HTTP.get(URI.parse(uri))\r\n        return true if page.match(/browser is configured to use Tor/i)\r\n      rescue\r\n        ;\r\n      end\r\n\r\n      false\r\n    end\r\n\r\n\r\n    # Our use case has the Tor SOCKS5 proxy running locally.  On unix, we use\r\n    # `lsof` to see the ports `tor` is listening on.\r\n    def self.find_tor_ports\r\n      p = `lsof -i tcp | grep \"^tor\" | grep \"\\(LISTEN\\)\"`\r\n      p.each_line.map do |l|\r\n        m = l.match(/localhost:([0-9]+) /)\r\n        m[1].to_i\r\n      end\r\n    end\r\n\r\n\r\n    # Configures future connections to use the Tor proxy, or raises TorError\r\n    def self.auto_configure!\r\n      return true if @configured\r\n\r\n      TCPSocket::socks_server = 'localhost'\r\n\r\n      ports = find_tor_ports\r\n\r\n      ports.each do |p|\r\n        TCPSocket::socks_port = p\r\n        if test_tor?\r\n          @configured = true\r\n          return true\r\n        end\r\n      end\r\n\r\n      TCPSocket::socks_server = nil\r\n      TCPSocket::socks_port = nil\r\n      fail TorError, \"SOCKS5 connection failed; ports: #{ports}\"\r\n    end\r\n  end\r\nend\r\n\r\n```\r\n\r\nAll set.  We'll just call that early in the process.\r\n\r\n\r\nThe Captcha\r\n-----------\r\n\r\nNow we get to the meat of the article: breaking the Silk Road Captcha.  \r\n\r\nI had never done this before, so I thought it'd be interesting.  The following\r\nis the result of two, six-hour sessions of hacking after work.\r\n\r\nI planned on calling this a success if I could hit better than one-third accuracy,\r\nas I doubted so few fails would set off any alarms.  Also, the site session\r\nwould allow me to get a lot of mileage out of one successful login.\r\n\r\nI ended up being able to do a lot better than that.\r\n\r\nBecause the Silk Road developers had to be paranoid, they couldn't use an\r\nexternal captcha service like ReCaptcha.  I'm not sure if the solution they used\r\nwas hand-rolled, or if they employed a third-party library, but lets give it a\r\nlook:\r\n\r\n![compa440](./images/compa440.jpg)\r\n\r\n![kingp176](./images/kingp176.jpg)\r\n\r\n![lux90](./images/lux90.jpg)\r\n\r\n![overt775](./images/overt775.jpg)\r\n\r\n![rompi4](./images/rompi4.jpg)\r\n\r\nThere are a few obvious features of this captcha:\r\n\r\n  1. A regular format: a dictionary word, truncated to at most five\r\n     characters, followed by an integer between 0 and 999.\r\n  2. The font doesn't change, ever.\r\n  3. Each character can be at any position on the Y axis.\r\n  4. Each character can be rotated, but seemingly only a few degrees.\r\n  5. The background is some sort of spiral, which doesn't contrast too much\r\n     with the lettering.\r\n  6. They're all awfully pink, so there's effectively one channel of color\r\n     information.\r\n\r\n\r\nI wrote a Mechanize tool that downloaded 2,000 captcha examples from the site:\r\none every two seconds.  Then I solved them all by hand, renaming the files to\r\n*(solution)*`.jpg`.  \r\n\r\nThat was not the most fun part of the process, but I ended up with a pretty\r\ndecent corpus of solved captchas to train or test against.\r\n\r\n\r\nRemoving the Background\r\n-----------------------\r\nAs good a place as any to start.  In this step, I want to end up with a\r\ngrayscale image, containing (mostly) only the characters, with the \"noise\"\r\nremoved.\r\n\r\nUsing The Gimp, I played around with a few effects, and a few different orders\r\nof effects.  It took some tweaking and trial and error, but here's what I ended\r\nup with:\r\n\r\nOriginal:\r\n\r\n![Original](./images/compa440.jpg)\r\n\r\nEqualized:\r\n\r\n![Equalized](./images/equalized.png)\r\n\r\nThreshold, 0.09:\r\n\r\n![Threshold](./images/threshold.png)\r\n\r\n*Note: Images altered manually for illustration.*\r\n\r\nThat corresponded to the following RMagick incantation:\r\n\r\n```ruby\r\n# Basic image processing gets us to a black and white image\r\n# with most background removed\r\ndef remove_background(im)\r\n  im = im.equalize\r\n  im = im.threshold(Magick::MaxRGB * 0.09)\r\n\r\n  # the above processing leaves a black border.  Remove it.\r\n  im = im.trim '#000'\r\n  im\r\nend\r\n```\r\n\r\n\r\nThat cleaned us up a lot, but there are still a lot of \"speckles\" left: little\r\none-pixel islands that can catch us up later, let's get rid of those:\r\n\r\n\r\n```ruby\r\n# Consider a pixel \"black enough\"?  In a grayscale sense.\r\ndef black?(p)\r\n  return p.intensity == 0 || (Magick::MaxRGB.to_f / p.intensity) < 0.5\r\nend\r\n\r\n\r\n# True iff [x,y] is a valid pixel coordinate in the image\r\ndef in_bounds?(im, x, y)\r\n  return x >= 0 && y >= 0 && x < im.columns && y < im.rows\r\nend\r\n\r\n\r\n# Returns new image with single-pixel \"islands\" removed,\r\n#   see: Conway's game of life.\r\ndef despeckle(im)\r\n  xydeltas = [[-1, -1],  [0, -1], [+1, -1],\r\n              [-1,  0],           [+1,  0],\r\n              [-1, +1],  [0, +1], [+1, +1]]\r\n\r\n  j = im.dup\r\n  j.each_pixel do |p, x, y|\r\n    if black?(p)\r\n      island = true\r\n\r\n      xydeltas.each do |dx2, dy2|\r\n        if in_bounds?(j, x + dx2, y + dy2) &&\r\n            black?(j.pixel_color(x + dx2, y + dy2))\r\n          island = false\r\n          break\r\n        end\r\n      end\r\n\r\n      im = im.color_point(x, y, '#fff') if island\r\n\r\n    end\r\n  end\r\n\r\n  im\r\nend\r\n```\r\n\r\nWe end up with something like the following:\r\n\r\n![Final Processed Image](./images/despeckled.png)\r\n\r\nAwesome.\r\n\r\nI considered taking these processed images and piping them through OCR software,\r\nbut experiments showed that approach lacking.  There was more work to do.\r\n\r\n\r\nSegmenting\r\n----------\r\nNow I want to slice the image up into a list of bitmaps, each holding one\r\ncharacter.  We travel the image, left to right, looking for blank columns.\r\n\r\n```ruby\r\n# returns true if column \"x\" is blank (non-black)\r\ndef blank_column?(im, x)\r\n  (0 ... im.rows).each do |y|\r\n    return false if black?(im.pixel_color(x, y))\r\n  end\r\n\r\n  true\r\nend\r\n\r\n# finds columns of white, and splits the image into characters, yielding each\r\ndef each_segmented_character(im)\r\n  return enum_for(__method__, im) unless block_given?\r\n\r\n  st = 0\r\n  x  = 0\r\n  while x < im.columns\r\n    # Zoom over to the first non-blank column\r\n    x += 1 while x < im.columns && blank_column?(im, x)\r\n\r\n    # That's now our starting point.\r\n    st = x\r\n\r\n    # Zoom over to the next blank column, or end of the image.\r\n    x += 1 while x < im.columns && (!blank_column?(im, x) || (x - st < 2))\r\n\r\n    # slivers smaller than this can't possibly work: it's noise.\r\n    if x - st >= 4\r\n      # The crop/trim here also removes vertical whitespace, which puts the\r\n      # resulting bitmap into its minimal bounding box.\r\n      yield im.crop(st, 0, x - st, im.rows).trim('#fff')\r\n    end\r\n  end\r\nend\r\n\r\n```\r\n\r\nThis breaks up the image into segments like the following, horizontally:\r\n\r\n![Segmented image](./images/segmented.png)\r\n\r\nAnd then computed each character's bounding box, to put its origin at the\r\ntop-left.\r\n\r\nI ran this process over the corpus, and generated the \"average\" representation\r\nof each character, grouped by the captcha solutions I had solved by hand.  This\r\nended being a good visualization for later.\r\n\r\n![The extracted \"font\"](./images/font-extracted.png)\r\n\r\nThink of it as a histogram.  Darker areas are where my segmentation algorithm\r\nsliced the characters in such a way that they \"agreed\".  You can see offsets\r\nwhere the pre-processing occasioanlly allowed some things slip through the\r\nthresholds, too.\r\n\r\nOn the whole, every one is pretty readable.  As the letters came from an English\r\ndictionary, common letters are better represented (darker) than those that occur\r\nless frequently in the language.  I use this to my advantage later.\r\n\r\nBet you didn't know *J* was so rare.\r\n\r\n\r\nA Neural Network for Character Recognition\r\n------------------------------------------\r\nThere's a cool gem for Ruby called [AI4R](http://www.ai4r.org/).  It's got\r\ngenetic algorithm implementations, Bayes classifiers, amongst other useful\r\nthings.  As  `Ai4r::Positronic` was not available at the time, I decided to attack this\r\nwith a neural network.\r\n\r\nBasically, you start with an empty array of bits.  You *train* it with a\r\npattern and a known solution: e.g.,\r\n\r\n  * \"This pattern represents an *a*.\",\r\n  * \"This different pattern also represents an *a*.\"  \r\n  * \"This pattern represents a *b*.\"\r\n\r\nAfter enough examples, you can present a candidate pattern, and the network will\r\ntell you what it *probably* represents, using its training.\r\n\r\nThere are some trade-offs.  The larger your bitstring, and the more elaborate\r\nlayer configuration you use can have dramatic effects on the training runtime.\r\n\r\nI took each character in the corpus, cropped to 20x20, and applied a monochrome\r\nthreshold to end up with a truly 1bpp representation, and started training.\r\n\r\n```ruby\r\nrequire 'ai4r'\r\nrequire 'RMagick'\r\n\r\nmodule Sr\r\n  class Brain\r\n    def initialize\r\n      @keys  = *(('a'..'z').to_a + ('0'..'9').to_a)\r\n      @ai = Ai4r::NeuralNetwork::Backpropagation.new([GRID_SIZE * GRID_SIZE,\r\n                                                      @keys.size])\r\n    end\r\n\r\n    # Returns a flat array of 0 or 1 from the image data, suitable for\r\n    # feeding into the neural network\r\n    def to_data(image)\r\n      # New image of our actual grid size, then paste it over\r\n      padded = Magick::Image.new(GRID_SIZE, GRID_SIZE)\r\n      padded = padded.composite(image,\r\n                                Magick::NorthWestGravity,\r\n                                Magick::MultiplyCompositeOp)\r\n\r\n      padded.get_pixels(0, 0, padded.columns, padded.rows).map do |p|\r\n        ImageProcessor.black?(p) ? 1 : 0\r\n      end\r\n    end\r\n\r\n    # Feed this a positive example, e.g., train('a', image)\r\n    def train(char, image)\r\n      outputs = [0] * @keys.length\r\n      outputs[ @keys.index(char) ] = 1.0\r\n      @ai.train(to_data(image), outputs)\r\n    end\r\n\r\n    # Return all guesses, e.g., {'a' => 0.01, 'b' => '0.2', ...}\r\n    def classify_all(image)\r\n      results = @ai.eval(to_data(image))\r\n      r = {}\r\n      @keys.each.with_index do |v, i|\r\n        r[v] = results[i]\r\n      end\r\n      r\r\n    end\r\n\r\n    # Returns best guess\r\n    def classify(image)\r\n      res = @ai.eval(to_data(image))\r\n      @keys[res.index(res.max)]\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nAt this point, I modified my Mechanize tool to continue downloading captchas. Only\r\nthis time, it tried to solve them, and got feedback by attempting a login.  \r\n\r\nThe ones it got correct were added to the corpus of solutions, as a way to\r\nself-reinforce its knowledge.\r\n\r\nWhen a login attempt failed, it saved the captcha to a directory, so that I\r\ncould solve it manually.  Once the tool noticed I had renamed the file, it\r\nslurped it up, and added it to the corpus to train upon.  Every now and then I'd\r\nsolve a few dozen captchas.\r\n\r\nAfter a few hours of training, the per-character success rate was at 90%. Unfortunately,\r\nthe average captcha was eight characters long, so its successful\r\nlogin rate, considering *all* characters had to be correct, was 0.90 \\*\\* 8, or\r\n43%.  The goal was already met, but this could be better.\r\n\r\n\r\nAbusing the Dictionary and Exploiting the Letter Frequency of the English Language\r\n----------------------\r\nWell, the \"word\" part of the captcha wasn't just random letters, they were\r\nwords.  Truncated words from a word list.  I have a word list, and I can\r\nprobably build one bigger than theirs with a bit of searching:\r\n\r\n```bash\r\ncat /usr/share/dict/words *.txt | tr A-Z a-z | grep -v '[^a-z]' \\\r\n  | cut -c1-5 | grep '...' | sort | uniq > dict5.txt\r\n```\r\n\r\nNow, assuming that my `dict5.txt` will contain every possible \"word\" part a\r\ncaptcha solution will contain, the client will at least know when it's not even\r\nworth a try.\r\n\r\nThe neural network came up with a candidate solution, but it's weird.  It\r\ndoesn't fit the format, or came up with a word that's not in its list.  How many\r\nof those can be fixed?\r\n\r\n```ruby\r\n# Returns the \"word\" and \"number\" part of a captcha separately.\r\n# \"word\" takes the longest possible match\r\ndef split_word(s)\r\n  s.match(/(.+?)?(\\d+)?\\z/.to_a.last(2) rescue [nil, nil]\r\nend\r\n\r\ndef weird_word?(s)\r\n  w, d = split_word(s)\r\n\r\n  # nothing matched?\r\n  return true if w.nil? || d.nil?\r\n\r\n  # Digit in word part?, Too long?\r\n  return true if w.match /\\d/ || w.size > 5\r\n\r\n  # Too many digits?\r\n  return true if d.size > 3\r\n\r\n  # Yay\r\n  return false\r\nend\r\n\r\ndef in_dict?(w)\r\n  return dict.bsearch { |p| p >= w } == w\r\nend\r\n```\r\n\r\nThe initial plan was to start looking at use the neural network's \"runner up\"\r\nanswers, but something else proved far more effective.\r\n\r\nHere's an interesting table:\r\n```ruby\r\n# a-z English text letter frequency, according to Wikipedia\r\nLETTER_FREQ = {\r\n  a: 0.08167, b: 0.01492, c: 0.02782, d: 0.04253, e: 0.12702, f: 0.02228,\r\n  g: 0.02015, h: 0.06094, i: 0.06966, j: 0.00153, k: 0.00772, l: 0.04025,\r\n  m: 0.02406, n: 0.06749, o: 0.07507, p: 0.01929, q: 0.00095, r: 0.05987,\r\n  s: 0.06327, t: 0.09056, u: 0.02758, v: 0.00978, w: 0.02360, x: 0.00150,\r\n  y: 0.01974, z: 0.00074\r\n}\r\n\r\n```\r\n\r\nNotice our poor under-represented *J* again?\r\n\r\nPeter Norvig has a useful article, [How to Write a Spelling Corrector](http://norvig.com/spell-correct.html).  I\r\nhad a dictionary and a probably-mispelled word.  So lets try it, with a twist:\r\n\r\n```ruby\r\n# This finds every dictionary entry that is a single replacement away from\r\n# word.  It returns in a clever priority: it tries to replace digits first,\r\n# then the alphabet, in z..e (frequency) order. As we're just focusing on the\r\n# \"word\" part, \"9\" is most definitely a mistake, and \"z\" is more likely a\r\n# mistake than \"e\".\r\n\r\ndef edit1(word)\r\n  # Inverse frequency, \"zq...e\"\r\n  letter_freq = LETTER_FREQ.sort_by { |k, v| v }.map(&:first).join\r\n\r\n  # Total replacement priority: 0..9zq..e\r\n  replacement_priority = ('0'..'9').to_a.join + letter_freq\r\n\r\n  # Generate splits, tagged with the priority, then sort them so\r\n  # the splits on least-frequent english characters get processed first\r\n  splits = word.each_char.with_index.map do |c, i|\r\n    # Replace what we're looking for with a space\r\n    w = word.dup;\r\n    w[i] = ' '\r\n    [replacement_priority.index(c), w]\r\n  end\r\n  splits.sort_by!{|k,v| k}.map!(&:last)\r\n\r\n  # Keep up with results so we don't end up with duplicates\r\n  yielded = []\r\n  splits.each do |w|\r\n    letter_freq.each_char do |c|\r\n      candidate = w.sub(' ', c)\r\n      next if yielded.include?(candidate)\r\n\r\n      if in_dict?(candidate)\r\n        yielded.push(candidate)\r\n        yield candidate\r\n      end\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nThe big trick here is the replacement order.  Using the table of letter\r\nfrequencies, and the list of valid dictionary words that are one edit away from\r\nwhat the neural network proposed, we really want to prefer replacing a *z* before\r\na vowel.\r\n\r\nThis \"fix-up\" step took the successful login rate from 43% to 56%.  That's when\r\nI considered it solved and called it day.  \r\n\r\nThe experiment didn't end up going much further (and I don't have that data!), but\r\nit was a nice stroll around quite a few problem domains.\r\n\r\n\\- [mieko](http://mike.filespanker.com/)\r\n\r\nAbout the Author\r\n----------------\r\nMike is amazing, and sometimes accepts well-paying, remote, software gigs.\r\n","google":"UA-2490854-2","note":"Don't delete this file! It's used internally to help with page regeneration."}